[2m2025-09-13T01:40:41.403471Z[0m [32m INFO[0m [2mbench[0m[2m:[0m Using API base URL: https://sudoapp.dev/api
[2m2025-09-13T01:40:42.014932Z[0m [32m INFO[0m [2mbench::benchmarks[0m[2m:[0m Loaded 93 supported models
[2m2025-09-13T01:40:42.014956Z[0m [32m INFO[0m [2mbench::benchmarks[0m[2m:[0m Running latency benchmark on 13 models
[2m2025-09-13T01:40:42.014984Z[0m [32m INFO[0m [2mbench::benchmarks[0m[2m:[0m Testing model: gpt-4o
[2m2025-09-13T01:40:45.913645Z[0m [32m INFO[0m [2mbench::benchmarks[0m[2m:[0m Testing model: gpt-4o-mini
[2m2025-09-13T01:40:48.283914Z[0m [32m INFO[0m [2mbench::benchmarks[0m[2m:[0m Testing model: gpt-5-nano
[2m2025-09-13T01:40:51.797580Z[0m [32m INFO[0m [2mbench::benchmarks[0m[2m:[0m Testing model: o3
[2m2025-09-13T01:40:54.645212Z[0m [32m INFO[0m [2mbench::benchmarks[0m[2m:[0m Testing model: claude-3-7-sonnet-20250219
[2m2025-09-13T01:40:58.907310Z[0m [32m INFO[0m [2mbench::benchmarks[0m[2m:[0m Testing model: claude-sonnet-4-20250514
[2m2025-09-13T01:41:05.293315Z[0m [32m INFO[0m [2mbench::benchmarks[0m[2m:[0m Testing model: claude-3-haiku-20240307
[2m2025-09-13T01:41:06.551921Z[0m [32m INFO[0m [2mbench::benchmarks[0m[2m:[0m Testing model: grok-3
[2m2025-09-13T01:41:14.370567Z[0m [32m INFO[0m [2mbench::benchmarks[0m[2m:[0m Testing model: grok-4-0709
[2m2025-09-13T01:41:18.572121Z[0m [32m INFO[0m [2mbench::benchmarks[0m[2m:[0m Testing model: gemini-2.5-flash
[2m2025-09-13T01:41:20.141834Z[0m [32m INFO[0m [2mbench::benchmarks[0m[2m:[0m Testing model: gemini-2.0-flash
[2m2025-09-13T01:41:21.669307Z[0m [32m INFO[0m [2mbench::benchmarks[0m[2m:[0m Testing model: gemini-2.0-flash-lite
[2m2025-09-13T01:41:23.264316Z[0m [32m INFO[0m [2mbench::benchmarks[0m[2m:[0m Testing model: deepseek-chat

Streaming Latency Benchmark Results
============================================================

ðŸ¤– Model: gemini-2.5-flash
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
StreamingStats {
    model: "gemini-2.5-flash",
    request_count: 10,
    mean_time_to_first_chunk: 447.033595ms,
    p95_time_to_first_chunk: 534.569541ms,
    mean_tokens_per_second: 0.0,
    total_chunks: 10,
    error_rate: 0.0,
}

ðŸ¤– Model: gemini-2.0-flash-lite
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
StreamingStats {
    model: "gemini-2.0-flash-lite",
    request_count: 10,
    mean_time_to_first_chunk: 402.937187ms,
    p95_time_to_first_chunk: 639.509417ms,
    mean_tokens_per_second: 16.14434836229692,
    total_chunks: 38,
    error_rate: 0.0,
}

ðŸ¤– Model: deepseek-chat
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
StreamingStats {
    model: "deepseek-chat",
    request_count: 10,
    mean_time_to_first_chunk: 2.825998887s,
    p95_time_to_first_chunk: 3.054149042s,
    mean_tokens_per_second: 12.280415212265082,
    total_chunks: 915,
    error_rate: 0.0,
}

ðŸ¤– Model: gpt-5-nano
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
StreamingStats {
    model: "gpt-5-nano",
    request_count: 10,
    mean_time_to_first_chunk: 1.00301077s,
    p95_time_to_first_chunk: 1.4135215s,
    mean_tokens_per_second: 7.883195416404159,
    total_chunks: 40,
    error_rate: 0.0,
}

ðŸ¤– Model: o3
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
StreamingStats {
    model: "o3",
    request_count: 10,
    mean_time_to_first_chunk: 911.12497ms,
    p95_time_to_first_chunk: 1.288360667s,
    mean_tokens_per_second: 8.646359505807284,
    total_chunks: 40,
    error_rate: 0.0,
}

ðŸ¤– Model: gpt-4o
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
StreamingStats {
    model: "gpt-4o",
    request_count: 10,
    mean_time_to_first_chunk: 824.627912ms,
    p95_time_to_first_chunk: 1.405565458s,
    mean_tokens_per_second: 8.803728063044973,
    total_chunks: 120,
    error_rate: 0.0,
}

ðŸ¤– Model: grok-4-0709
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
StreamingStats {
    model: "grok-4-0709",
    request_count: 10,
    mean_time_to_first_chunk: 1.720807187s,
    p95_time_to_first_chunk: 1.784498375s,
    mean_tokens_per_second: 0.0,
    total_chunks: 100,
    error_rate: 0.0,
}

ðŸ¤– Model: gemini-2.0-flash
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
StreamingStats {
    model: "gemini-2.0-flash",
    request_count: 10,
    mean_time_to_first_chunk: 380.920808ms,
    p95_time_to_first_chunk: 412.927958ms,
    mean_tokens_per_second: 17.591154362615253,
    total_chunks: 40,
    error_rate: 0.0,
}

ðŸ¤– Model: claude-3-7-sonnet-20250219
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
StreamingStats {
    model: "claude-3-7-sonnet-20250219",
    request_count: 10,
    mean_time_to_first_chunk: 1.189029437s,
    p95_time_to_first_chunk: 2.493834084s,
    mean_tokens_per_second: 6.074878131691351,
    total_chunks: 50,
    error_rate: 0.0,
}

ðŸ¤– Model: grok-3
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
StreamingStats {
    model: "grok-3",
    request_count: 10,
    mean_time_to_first_chunk: 1.07220092s,
    p95_time_to_first_chunk: 2.196311584s,
    mean_tokens_per_second: 6.020461025355081,
    total_chunks: 100,
    error_rate: 0.0,
}

ðŸ¤– Model: claude-sonnet-4-20250514
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
StreamingStats {
    model: "claude-sonnet-4-20250514",
    request_count: 10,
    mean_time_to_first_chunk: 2.271213495s,
    p95_time_to_first_chunk: 3.763280917s,
    mean_tokens_per_second: 3.3939873400580405,
    total_chunks: 50,
    error_rate: 0.0,
}

ðŸ¤– Model: claude-3-haiku-20240307
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
StreamingStats {
    model: "claude-3-haiku-20240307",
    request_count: 10,
    mean_time_to_first_chunk: 372.77712ms,
    p95_time_to_first_chunk: 446.564917ms,
    mean_tokens_per_second: 18.30971919388876,
    total_chunks: 52,
    error_rate: 0.0,
}

ðŸ¤– Model: gpt-4o-mini
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
StreamingStats {
    model: "gpt-4o-mini",
    request_count: 10,
    mean_time_to_first_chunk: 505.510595ms,
    p95_time_to_first_chunk: 998.1015ms,
    mean_tokens_per_second: 12.873369367051723,
    total_chunks: 120,
    error_rate: 0.0,
}
